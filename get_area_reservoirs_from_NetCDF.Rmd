```{r}

library(dplyr)
library(raster)
library(ncdf4)
library(maptools)
library(foreign)
library(RNetCDF)
library(rgdal)
library(lubridate)
library(tidyverse)


wd <- "C:/Users/gusta/Desktop/PhD/RS of Reservoirs/Tmax/"
shp_path <- "C:/Users/gusta/Desktop/PhD/RS of Reservoirs/"
shapefile <- "StreetLightLakes.shp"
```


```{r}
library(sf)
nc <- st_read(paste0(shp_path,shapefile)) #%>% 
              #  st_transform(32617)
nc
# using rgeos
sp_cent <- rgeos::gCentroid(as(nc, "Spatial"), byid = TRUE)

# using sf
sf_cent <- st_centroid(nc)

ggplot() + 
  geom_sf(data = nc, fill = 'white') +
  geom_sf(data = sp_cent %>% st_as_sf, color = 'blue') + 
  geom_sf(data = sf_cent, color = 'red') 
```


```{r}

#NetCDF_Extract <- function(shapefile) { 

# Basin = name of folder in which you'll save the data, such as "Merced River" #shapefile = name of the shapefile you'll use, as mentioned in line 9

# Let's loop through 2006-2099

# If you want just one GCM, one RCP scenario or one variable, you can just "mute" (#) the undesired ones by commenting them out in the first lines of this function, before the loop for the years
 for(year in 2000){
# Read in the netCDF data 
dpath <- paste0(wd,"tmmx_",as.character(year),".nc")

file <- brick(dpath)
# Give me the number of layers in netCDF data
nl <- nlayers(file) 

# Set the dataframe we want, to be a list, in order to store all results of the loops
df = list() 

#Set the subbasin we want, to be a list, in order to store all results of the loops

for (layers in 1:nl){
  
  # Extract the raster file of layers
  r <- raster(file, layer = layers)
  
  # Extract relevant information from shapefile
  shp_file <- shapefile(paste0(shp_path,shapefile))
  # shp_file$SUBWAT <- gsub("^.{0,4}", "sb", shp_file$SUBWAT) #switch names in the attribute table of the shp file (example: MER_O1, MER_02, etc, will become sb01, sb02, etc)
  #these shapefiles have basin names as MER_01, MER_02, etc. So, here I'm selecting the first 4 digits, and switching them for "sb", so that I can use this attributes later to split the .csv file directly by subbasin, already with the same labels we currently have on Box
  shp <- shp_file["NAME"]
  
  # Extract the mean value of cells within the polygons
  # Alternative: look to "mask" function ?mask
  masked_file<-raster::extract(r, #extract function is very computationally heavy
                               shp, #shapefile
                               fun = mean, #this gives the mean observed values in the region, if fun = NULL, we will have values for each point, with the respective weight for each point
                               na.rm=TRUE, 
                               df=T, #as a dataframe
                               small=T, #return a number, also when the buffer does not include the center of a single cell
                               sp=T,  #extracted values are added to the data.frame
                               weights=TRUE, #the function returns, for each polygon, a matrix with the cell values and the approximate fraction of each cell that is covered by the polygon
                               normalizedweights=TRUE) #weights are normalized (they add up to 1 for each polygon)
  
  # Generate variable depicting the date
  # Extract the information about the time
  
  casted <- data.frame(masked_file) %>% melt(.) %>% mutate(variable = as.Date(as.numeric(substring(variable,2)),origin = "1900-01-01"), value = (((value- 273.15)*9/5) + 32 )) %>% dcast(., variable~NAME) %>% rename(Date = variable)


  
  # rename column with the variable that represents the extracted values
  
  
  #here I'm diving by 1,000 and 86400 seconds to make mm/day become m/s, then multiplying by the area of the subbasin (m2) to get m3/s
  
  # save data as .csv
  write.table(casted, #vector we want to save
              file= paste0("tmax_CA_reservoirs_","\u2109",".csv"), #save csv files per basin using the basin "name"
              append=TRUE, #this gathers all the loop's results, if FALSE we'll have results being overwritten over and over again in the first line
              sep=",",
              col.names=!file.exists(paste0("tmax_CA_reservoirs_","\u2109",".csv")), #if we set as TRUE, we'll have headings repeated per each row, in this way we just have one heading
              row.names=FALSE, #no names for rows
              quote = FALSE) #no column with quotes
}
}

#}
```

```{r}

NetCDF_Extract("StreetLightLakes.shp")
```